{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir('./data') if isfile(join('./data', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_files =  ['realDonaldTrump', 'SecretaryCarson','MartinOMalley', 'JebBush',\n",
    "             'BarackObama', 'HillaryClinton','BernieSanders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Trump': 12924, 'NoTrump': 12924})\n"
     ]
    }
   ],
   "source": [
    "text = list()\n",
    "labels = list()\n",
    "data_source = defaultdict(int)\n",
    "total_count = 12924\n",
    "not_count = 0\n",
    "for file in onlyfiles:        \n",
    "    with open('data/' + file, newline='', encoding=\"utf8\") as csv_file:\n",
    "        if file[:-11] not in selected_files and 'trump' not in file.lower():\n",
    "            continue                \n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        if 'trump' not in file.lower():\n",
    "            label = 'NoTrump'\n",
    "            if not_count == total_count:\n",
    "                continue\n",
    "        else:\n",
    "            label = 'Trump'        \n",
    "        text_ind = 1\n",
    "        if \"MORE_TRUMP.csv\" in file:\n",
    "            text_ind = 0\n",
    "            source = 'realDonaldTrump'\n",
    "        else:\n",
    "            source = file[:-11]        \n",
    "        for row in csv_reader:            \n",
    "            if line_count != 0:\n",
    "                line = re.sub('[\\s\\n\\t#@]+', ' ', row[text_ind]).strip()\n",
    "                line = re.sub(r'http\\S+', '', line).strip()            \n",
    "                if len(line) == 0:\n",
    "                    continue                    \n",
    "                text.append(line)                \n",
    "                labels.append(label)            \n",
    "                data_source[source] += 1\n",
    "                if label != 'Trump':\n",
    "                    not_count += 1\n",
    "                    if not_count == total_count:\n",
    "                        break                \n",
    "            line_count += 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels = \\\n",
    "train_test_split(text, labels, test_size=0.3, random_state=42)\n",
    "with open(\"train.csv\", \"w\", newline='', encoding='utf8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for i in range(len(train_data)):\n",
    "        csv_writer.writerow([train_data[i], train_labels[i]])\n",
    "with open(\"dev.csv\", \"w\", newline='', encoding='utf8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for i in range(len(test_data)):\n",
    "        csv_writer.writerow([test_data[i], test_labels[i]])\n",
    "from collections import Counter    \n",
    "print(Counter(labels))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'realDonaldTrump': 12924,\n",
       "             'SecretaryCarson': 1242,\n",
       "             'MartinOMalley': 2211,\n",
       "             'JebBush': 2757,\n",
       "             'BarackObama': 2880,\n",
       "             'HillaryClinton': 1774,\n",
       "             'BernieSanders': 2060})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Difficulty clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "def get_word_difficulty(word):\n",
    "    URL = \"https://datayze.com/word-analyzer.php\"      \n",
    "    PARAMS = {'word':word}   \n",
    "    # sending get request and saving the response as response object \n",
    "    r = requests.get(url = URL, params = PARAMS) \n",
    "    misspell_text = re.findall('<tr><td class=\"indented\">Misspelled.*</tr>', str(r.content))\n",
    "    misspell_value_text = re.findall('<span class=\"value\">.* </span>', misspell_text[0])[0]   \n",
    "    print(misspell_value_text)\n",
    "    if 'Yes' in misspell_value_text:\n",
    "        return None\n",
    "    grade_text = re.findall('<td class=\"indented\">Grade Level.*</td>', str(r.content))\n",
    "    value_text = re.findall('<td><span class=\"value\">.*</span></td></tr>', grade_text[0])[0]\n",
    "    return value_text[24: value_text.index('</span>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_list = set()\n",
    "sat_list = set()\n",
    "toefl_list = set()\n",
    "gre_list = set()\n",
    "with open('vocabulary/primary_vocab.txt', 'r') as f:    \n",
    "    for line in f:\n",
    "        if line is not None:\n",
    "            words = tokenizer.tokenize(line)\n",
    "            for i in range(len(words)):\n",
    "                words[i] = ps.stem(words[i])\n",
    "            primary_list.update(words)\n",
    "with open('vocabulary/SAT_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "         if line is not None:\n",
    "            words = tokenizer.tokenize(line)\n",
    "            for i in range(len(words)):\n",
    "                words[i] = ps.stem(words[i])\n",
    "            sat_list.add(words[0])\n",
    "with open('vocabulary/TOEFL_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "         if line is not None:\n",
    "            words = tokenizer.tokenize(line)\n",
    "            for i in range(len(words)):\n",
    "                words[i] = ps.stem(words[i])\n",
    "            toefl_list.update(words)\n",
    "with open('vocabulary/GRE_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "         if line is not None:\n",
    "            words = tokenizer.tokenize(line) \n",
    "            if len(words) == 0:\n",
    "                continue\n",
    "            for i in range(len(words)):\n",
    "                words[i] = ps.stem(words[i])\n",
    "            gre_list.add(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_level = dict()\n",
    "for file in onlyfiles:       \n",
    "    with open('data/' + file, newline='', encoding=\"utf8\") as csv_file:        \n",
    "        if file[:-11] not in selected_files and 'trump' not in file.lower():\n",
    "            continue     \n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')                \n",
    "        text_ind = 1\n",
    "        if \"MORE_TRUMP.csv\" in file:\n",
    "            text_ind = 0\n",
    "            source = 'realDonaldTrump'\n",
    "        else:\n",
    "            source = file[:-11]\n",
    "        if source not in words_level:\n",
    "            words_level[source] = defaultdict(int)\n",
    "        line_count = 0        \n",
    "        for row in csv_reader:\n",
    "            if line_count != 0:\n",
    "                line = re.sub('[\\s\\n\\t#@]+', ' ', row[text_ind])\n",
    "                line = re.sub(r'http\\S+', '', line).strip()            \n",
    "                if len(line) == 0:\n",
    "                    continue\n",
    "                words = tokenizer.tokenize(row[text_ind])\n",
    "                for w in words:\n",
    "                    w = ps.stem(w)                    \n",
    "                    value = 'others'\n",
    "                    if w in gre_list:\n",
    "                        value = 'GRE' \n",
    "                    elif w in toefl_list:\n",
    "                        value = 'TOEFL' \n",
    "                    elif w in primary_list:\n",
    "                        value = 'primary'                                        \n",
    "                    words_level[source][value] += 1\n",
    "                    words_level[source]['total'] += 1\n",
    "            line_count += 1\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'realDonaldTrump': defaultdict(int,\n",
       "             {'TOEFL': 124530,\n",
       "              'total': 340958,\n",
       "              'others': 54268,\n",
       "              'primary': 145408,\n",
       "              'GRE': 16752}),\n",
       " 'SecretaryCarson': defaultdict(int,\n",
       "             {'primary': 14905,\n",
       "              'total': 37792,\n",
       "              'TOEFL': 13765,\n",
       "              'others': 7448,\n",
       "              'GRE': 1674}),\n",
       " 'MartinOMalley': defaultdict(int,\n",
       "             {'primary': 19832,\n",
       "              'total': 47548,\n",
       "              'others': 11004,\n",
       "              'TOEFL': 15060,\n",
       "              'GRE': 1652}),\n",
       " 'JebBush': defaultdict(int,\n",
       "             {'primary': 23104,\n",
       "              'total': 56243,\n",
       "              'others': 13710,\n",
       "              'TOEFL': 17147,\n",
       "              'GRE': 2282}),\n",
       " 'BarackObama': defaultdict(int,\n",
       "             {'primary': 25305,\n",
       "              'total': 58141,\n",
       "              'TOEFL': 19206,\n",
       "              'others': 11737,\n",
       "              'GRE': 1893}),\n",
       " 'HillaryClinton': defaultdict(int,\n",
       "             {'primary': 20446,\n",
       "              'total': 45629,\n",
       "              'GRE': 1508,\n",
       "              'TOEFL': 15000,\n",
       "              'others': 8675}),\n",
       " 'BernieSanders': defaultdict(int,\n",
       "             {'primary': 31616,\n",
       "              'total': 72770,\n",
       "              'TOEFL': 28347,\n",
       "              'others': 10022,\n",
       "              'GRE': 2785})}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_percent = dict()\n",
    "for key, v_dict in words_level.items():    \n",
    "    if key not in word_percent:\n",
    "        word_percent[key] = defaultdict(float)\n",
    "    for cate, count in v_dict.items():\n",
    "        if cate == 'total':\n",
    "            continue\n",
    "        word_percent[key][cate] = count / words_level[key]['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'realDonaldTrump': defaultdict(float,\n",
       "             {'TOEFL': 0.36523560086579576,\n",
       "              'others': 0.1591632987054124,\n",
       "              'primary': 0.42646894925474693,\n",
       "              'GRE': 0.049132151174044895}),\n",
       " 'SecretaryCarson': defaultdict(float,\n",
       "             {'primary': 0.39439563928873833,\n",
       "              'TOEFL': 0.3642305249788315,\n",
       "              'others': 0.19707874682472482,\n",
       "              'GRE': 0.04429508890770534}),\n",
       " 'MartinOMalley': defaultdict(float,\n",
       "             {'primary': 0.4170943047026163,\n",
       "              'others': 0.2314292925044166,\n",
       "              'TOEFL': 0.31673256498696056,\n",
       "              'GRE': 0.03474383780600656}),\n",
       " 'JebBush': defaultdict(float,\n",
       "             {'primary': 0.410788898173995,\n",
       "              'others': 0.2437636683676191,\n",
       "              'TOEFL': 0.3048734953683125,\n",
       "              'GRE': 0.04057393809007343}),\n",
       " 'BarackObama': defaultdict(float,\n",
       "             {'primary': 0.43523503207719166,\n",
       "              'TOEFL': 0.33033487556113583,\n",
       "              'others': 0.20187131284291635,\n",
       "              'GRE': 0.032558779518756124}),\n",
       " 'HillaryClinton': defaultdict(float,\n",
       "             {'primary': 0.4480922220517653,\n",
       "              'GRE': 0.03304915733415153,\n",
       "              'TOEFL': 0.3287383023954064,\n",
       "              'others': 0.19012031821867673}),\n",
       " 'BernieSanders': defaultdict(float,\n",
       "             {'primary': 0.43446475195822454,\n",
       "              'TOEFL': 0.3895423938436169,\n",
       "              'others': 0.13772158856671704,\n",
       "              'GRE': 0.03827126563144153})}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('statistic/words_level.json', 'w') as fp:\n",
    "    json.dump(word_percent, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
