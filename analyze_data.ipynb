{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, operator\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['All', 'Trump', 'NoTrump']\n",
    "train_data = list()\n",
    "train_labels = list()\n",
    "data_source = {'realDonaldTrump': 12924,\n",
    "             'SecretaryCarson': 1242,\n",
    "             'MartinOMalley': 2211,\n",
    "             'JebBush': 2757,\n",
    "             'BarackObama': 2880,\n",
    "             'HillaryClinton': 1774,\n",
    "             'BernieSanders': 2060}\n",
    "text_length = {key: list() for key in labels}\n",
    "word_level = {key: defaultdict(int) for key in labels}\n",
    "unigram_count = {key: defaultdict(int) for key in labels}\n",
    "bigram_count = {key: defaultdict(int) for key in labels}\n",
    "trigram_count = {key: defaultdict(int) for key in labels}\n",
    "unigram_filter = {key: defaultdict(int) for key in labels}\n",
    "bigram_filter = {key: defaultdict(int) for key in labels}\n",
    "trigram_filter = {key: defaultdict(int) for key in labels}\n",
    "dev_data = list()\n",
    "dev_labels = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect statistics\n",
    "TODO: word difficulty classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = 'All'\n",
    "phrases = ['uni', 'bi', 'tri']\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "Trump_vocab = {key: defaultdict(int) for key in phrases}\n",
    "noTrump_vocab = {key: defaultdict(int) for key in phrases}\n",
    "line_count = 0\n",
    "with open('train.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')    \n",
    "    for row in csv_reader:\n",
    "        text = row[0]\n",
    "        label = row[1]\n",
    "        train_data.append(text)\n",
    "        train_labels.append(label)        \n",
    "        text_length[label].append(len(row[0]))        \n",
    "        words = tokenizer.tokenize(row[0])        \n",
    "        for unigram in words:\n",
    "            unigram_count[label][unigram] += 1\n",
    "            unigram_count[all_label][unigram] += 1\n",
    "        for bigram in list(nltk.bigrams(words)):\n",
    "            bigram_count[label][bigram] += 1\n",
    "            bigram_count[all_label][bigram] += 1\n",
    "        for trigram in list(nltk.trigrams(words)):\n",
    "            trigram_count[label][trigram] += 1\n",
    "            trigram_count[all_label][trigram] += 1\n",
    "            \n",
    "with open('dev.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')    \n",
    "    for row in csv_reader:                                \n",
    "        dev_data.append(row[0])\n",
    "        dev_labels.append(row[1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "label_counter = {'total': len(train_data), 'validation': len(dev_data)}\n",
    "label_counter.update(Counter(train_labels).most_common())\n",
    "for k, v in unigram_count.items():\n",
    "    unigram_count[k] = {vk: vv for (vk, vv) in sorted(v.items(), key=operator.itemgetter(1), reverse=True)}\n",
    "    unigram_filter[k] = dict(itertools.islice(unigram_count[k].items(), 0, 10))\n",
    "    unigram_filter[k].update(dict(itertools.islice(unigram_count[k].items(), len(unigram_count[k]) - 11, len(unigram_count[k]) - 1)))\n",
    "for k, v in bigram_count.items():\n",
    "    bigram_count[k] = {' '.join(vk): vv for (vk, vv) in sorted(v.items(), key=operator.itemgetter(1), reverse=True)}\n",
    "    bigram_filter[k] = dict(itertools.islice(bigram_count[k].items(), 10))\n",
    "    bigram_filter[k].update(dict(itertools.islice(bigram_count[k].items(), len(bigram_count[k]) - 11, len(bigram_count[k]) - 1)))\n",
    "for k, v in trigram_count.items():\n",
    "    trigram_count[k] = {' '.join(vk): vv for (vk, vv) in sorted(v.items(), key=operator.itemgetter(1), reverse=True)}\n",
    "    trigram_filter[k] = dict(itertools.islice(trigram_count[k].items(), 10))\n",
    "    trigram_filter[k].update(dict(itertools.islice(trigram_count[k].items(), len(trigram_count[k]) - 11, len(trigram_count[k]) - 1)))\n",
    "basic_dict = {'count': label_counter, 'length': text_length, 'source': data_source,\n",
    "              'unigram': unigram_count, 'bigram': bigram_count, 'trigram': trigram_count }            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('statistic/dataset_statistic.json', 'w') as fp:\n",
    "    json.dump(basic_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list()\n",
    "train_labels = list()\n",
    "dev_data = list()\n",
    "dev_labels = list()\n",
    "with open('train.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')    \n",
    "    for row in csv_reader:        \n",
    "        train_data.append(row[0])\n",
    "        train_labels.append(row[1])               \n",
    "            \n",
    "with open('dev.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')    \n",
    "    for row in csv_reader:                                \n",
    "        dev_data.append(row[0])\n",
    "        dev_labels.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Vectorizer(Enum):\n",
    "    \"\"\"Methods for feature extraction\"\"\"\n",
    "    Count = 1\n",
    "    TfIdf = 2\n",
    "\n",
    "\n",
    "class Arguments():\n",
    "    \"\"\" Store arguments from command lines. \"\"\"\n",
    "\n",
    "    def __init__(self):        \n",
    "        self.vectorizer = Vectorizer.Count\n",
    "        self.token_pattern = r'(?u)\\b\\w\\w+\\b'\n",
    "        self.ngram = 1        \n",
    "        self.min_df = 0.0\n",
    "        self.max_df = 1.0\n",
    "        self.lowercase = False\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "trainy = le.transform(train_labels)\n",
    "devy = le.transform(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def extract_feature(args, train_data, dev_data):\n",
    "    \"\"\"Extract feature vectors from train data.\n",
    "    \n",
    "    Use CountVectorizer or TfidfVectorizer.\n",
    "    \"\"\"\n",
    "    if args.ngram > 1:\n",
    "        args.token_pattern = r'\\b\\w+\\b'\n",
    "    if args.vectorizer is Vectorizer.Count:\n",
    "        vect = CountVectorizer(lowercase=args.lowercase, ngram_range=(\n",
    "            1, args.ngram), token_pattern=args.token_pattern, min_df=args.min_df, max_df=args.max_df)\n",
    "    elif args.vectorizer is Vectorizer.TfIdf:\n",
    "        vect = TfidfVectorizer(lowercase=args.lowercase, ngram_range=(\n",
    "            1, args.ngram), token_pattern=args.token_pattern, min_df=args.min_df, max_df=args.max_df)\n",
    "    trainX = vect.fit_transform(train_data)    \n",
    "    devX = vect.transform(dev_data)\n",
    "    return trainX, devX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "def train(X, y):\n",
    "    \"\"\"Train a classifie r using the given training data.\n",
    "\n",
    "    Trains logistic regression on the input data with default parameters.\n",
    "    \"\"\"        \n",
    "    cls = LogisticRegression(random_state=0, solver='lbfgs', max_iter=10000)\n",
    "    cls.fit(X, y)\n",
    "    return cls\n",
    "def evaluate(X, yt, cls, name='data'):\n",
    "    \"\"\"Evaluated a classifier on the given labeled data using accuracy.\"\"\"    \n",
    "    yp = cls.predict(X)\n",
    "    acc = metrics.accuracy_score(yt, yp)\n",
    "    print(\"  Accuracy on %s  is: %s\" % (name, acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train_data, dev_data, args):\n",
    "    \"\"\"Tune the hyper-parameters: n-gram, minimum count.\n",
    "\n",
    "    Use the approach of grid search.\n",
    "    \"\"\"    \n",
    "    best_acc = 0\n",
    "    best_f = Vectorizer.Count\n",
    "    best_n = 1\n",
    "    best_min = 0.0\n",
    "    best_max = 1.0\n",
    "    best_lowecase = False\n",
    "    with open(\"grid_search_2.csv\", \"w\", newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        # Tune n-gram and minumum count\n",
    "        csv_writer.writerow(\n",
    "            ['Tokenizer', 'lowercase', 'N-gram', 'Min_df', 'Max_df', 'Accuracy'])\n",
    "        for f in Vectorizer:\n",
    "            args.vectorizer = f\n",
    "            for lowercase in [False]:\n",
    "                args.lowercase = lowercase\n",
    "                for n in range(3, 4):\n",
    "                    args.ngram = n\n",
    "                    for min_v in range(, 1):\n",
    "                        args.min_df = min_v\n",
    "                        for max_v in range(310, 320, 100):\n",
    "                            args.max_df = max_v\n",
    "                            trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "                            cls = train(trainX, trainy)\n",
    "                            dev_acc = evaluate(devX, devy, cls)\n",
    "                            csv_writer.writerow([f, lowercase, n, min_v, max_v, dev_acc])\n",
    "                            if dev_acc > best_acc:\n",
    "                                best_lowercase = lowercase\n",
    "                                best_f = f\n",
    "                                best_acc = dev_acc\n",
    "                                best_n = n\n",
    "                                best_min = min_v\n",
    "                                best_max = max_v\n",
    "    args.vectorizer = best_f\n",
    "    args.min_df = best_min\n",
    "    args.ngram = best_n\n",
    "    args.max_df = best_max\n",
    "    args.lowercase = best_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy on data  is: 0.9325596389426176\n",
      "  Accuracy on data  is: 0.9261121856866538\n",
      "  Accuracy on data  is: 0.9325596389426176\n"
     ]
    }
   ],
   "source": [
    "args = Arguments()\n",
    "grid_search(train_data, dev_data, args)\n",
    "trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "cls = train(trainX, trainy)\n",
    "dev_acc = evaluate(devX, devy, cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write grid search results into Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = []\n",
    "args_count = Arguments()\n",
    "args_count.ngram = 2\n",
    "args_count.f = Vectorizer.Count\n",
    "args_count.min_df = 2\n",
    "args_count.max_df = 910\n",
    "args_count.lowercase = False\n",
    "args_tfidf = Arguments()\n",
    "args_tfidf.ngram = 3\n",
    "args_tfidf.f = Vectorizer.TfIdf\n",
    "args_tfidf.min_df = 2\n",
    "args_tfidf.max_df = 310\n",
    "args_tfidf.lowercase = False\n",
    "for args in [args_tfidf]:\n",
    "    trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "    cls = train(trainX, trainy)\n",
    "    yp = cls.predict(devX)\n",
    "    acc = metrics.accuracy_score(devy, yp)\n",
    "    recall = metrics.recall_score(devy, yp)\n",
    "    precision = metrics.precision_score(devy, yp)\n",
    "    f1 = metrics.f1_score(devy, yp)\n",
    "    para_dict.append({'accuracy': acc, 'recall': recall, 'precision': precision, 'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = para_dict[0]\n",
    "tfidf_dict = para_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = []\n",
    "rows_name = ['ngram', 'min', 'max']\n",
    "vects = ['Count', 'TF-IDF']\n",
    "with open('statistic/grid_search_typical.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    vect = None\n",
    "    one_dict = {}\n",
    "    temp_dict = {}\n",
    "    current_name = ''\n",
    "    current_index = 0\n",
    "    for row in csv_reader:\n",
    "        if row[0] in vects:\n",
    "            if vect is None or row[0] != vect:\n",
    "                vect = row[0]\n",
    "                one_dict = {'Vectorizer': vect, 'lowercase': 'False'}\n",
    "                if vect == vects[0]:                    \n",
    "                    one_dict.update({'score': count_dict})\n",
    "                else:\n",
    "                    one_dict.update({'score': tfidf_dict})\n",
    "                para_dict.append(one_dict)\n",
    "            temp_dict = {}\n",
    "            current_name = row[1]\n",
    "            one_dict.update({row[1]: temp_dict})            \n",
    "        else:            \n",
    "            for i, name in enumerate(rows_name):                \n",
    "                 if name == current_name:                    \n",
    "                    current_index = i + 2\n",
    "            temp_dict[row[current_index]] = row[-1]                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('statistic/performance.json', 'w') as fp:\n",
    "    json.dump(para_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "para_dict = []\n",
    "args_count = Arguments()\n",
    "args_count.ngram = 2\n",
    "args_count.f = Vectorizer.Count\n",
    "args_count.min_df = 2\n",
    "args_count.max_df = 910\n",
    "args_count.lowercase = False\n",
    "# args_tfidf = Arguments()\n",
    "# args_tfidf.ngram = 5\n",
    "# args_tfidf.f = Vectorizer.TfIdf\n",
    "# args_tfidf.min_df = 2\n",
    "# args_tfidf.max_df = 110\n",
    "# args_tfidf.lowercase = False\n",
    "for args in [args_count]:\n",
    "    trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "    cls = train(trainX, trainy)\n",
    "    yprob = cls.predict_proba(devX)        \n",
    "    yp = cls.predict(devX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = dict()\n",
    "false_positive = dict()\n",
    "true_negative = dict()\n",
    "false_negative = dict()\n",
    "for i in range(len(yp)):\n",
    "    if yp[i] == devy[i]:\n",
    "        if yp[i] == 0:\n",
    "            true_negative[i] = yprob[i]    \n",
    "        else:\n",
    "            true_positive[i] = yprob[i]\n",
    "    else:\n",
    "        if yp[i] == 0:\n",
    "            false_negative[i] = yprob[i]\n",
    "        else:\n",
    "            false_positive[i] = yprob[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = sorted(true_positive.items(), key=lambda x: x[1][1], reverse=True)\n",
    "false_positive = sorted(false_positive.items(), key=lambda x: x[1][1], reverse=True)\n",
    "true_negative = sorted(true_negative.items(), key=lambda x: x[1][1], reverse=True)\n",
    "false_negative = sorted(false_negative.items(), key=lambda x: x[1][1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "name_dict = {'true Trump': true_positive, 'false Trump': false_positive,\\\n",
    "             'true NoTrump': true_negative, 'false NoTrump': false_negative}\n",
    "instances = dict()\n",
    "for label, prob_dict in name_dict.items():\n",
    "    if label not in instances:\n",
    "        instances[label] = dict()    \n",
    "    count = 0\n",
    "    thre = 10\n",
    "    if label == 'true Trump':\n",
    "        thre += 1\n",
    "    for index, prob in prob_dict:                \n",
    "        if label == 'true Trump' and count == 0:\n",
    "            count += 1\n",
    "            continue        \n",
    "        if count >= thre:\n",
    "            break\n",
    "        instances[label][dev_data[index]] = [prob[0], prob[1]]\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('statistic/example_instances.json', 'w') as fp:\n",
    "    json.dump(instances, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
