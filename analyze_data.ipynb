{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, operator\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['All', 'Trump', 'NoTrump']\n",
    "train_data = list()\n",
    "train_labels = list()\n",
    "data_source = {'realDonaldTrump': 12322,\n",
    "             'SecretaryCarson': 1242,\n",
    "             'MartinOMalley': 2211,\n",
    "             'JebBush': 2757,\n",
    "             'BarackObama': 2880,\n",
    "             'HillaryClinton': 1774,\n",
    "             'BernieSanders': 1458}\n",
    "text_length = {key: list() for key in labels}\n",
    "word_level = {key: defaultdict(int) for key in labels}\n",
    "unigram_count = {key: defaultdict(int) for key in labels}\n",
    "bigram_count = {key: defaultdict(int) for key in labels}\n",
    "trigram_count = {key: defaultdict(int) for key in labels}\n",
    "unigram_filter = {key: defaultdict(int) for key in labels}\n",
    "bigram_filter = {key: defaultdict(int) for key in labels}\n",
    "trigram_filter = {key: defaultdict(int) for key in labels}\n",
    "dev_data = list()\n",
    "dev_labels = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect statistics\n",
    "TODO: word difficulty classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = 'All'\n",
    "phrases = ['uni', 'bi', 'tri']\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "Trump_vocab = {key: defaultdict(int) for key in phrases}\n",
    "noTrump_vocab = {key: defaultdict(int) for key in phrases}\n",
    "line_count = 0\n",
    "with open('train.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')    \n",
    "    for row in csv_reader:\n",
    "        text = row[0]\n",
    "        label = row[1]\n",
    "        train_data.append(text)\n",
    "        train_labels.append(label)        \n",
    "        text_length[label].append(len(row[0]))        \n",
    "        words = tokenizer.tokenize(row[0])\n",
    "        for unigram in words:\n",
    "            unigram_count[label][unigram] += 1\n",
    "            unigram_count[all_label][unigram] += 1\n",
    "        for bigram in list(nltk.bigrams(words)):\n",
    "            bigram_count[label][bigram] += 1\n",
    "            bigram_count[all_label][bigram] += 1\n",
    "        for trigram in list(nltk.trigrams(words)):\n",
    "            trigram_count[label][trigram] += 1\n",
    "            trigram_count[all_label][trigram] += 1\n",
    "            \n",
    "with open('dev.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')    \n",
    "    for row in csv_reader:                                \n",
    "        dev_data.append(row[0])\n",
    "        dev_labels.append(row[1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "label_counter = {'total': len(train_data), 'validation': len(dev_data)}\n",
    "label_counter.update(Counter(train_labels).most_common())\n",
    "for k, v in unigram_count.items():\n",
    "    unigram_count[k] = {vk: vv for (vk, vv) in sorted(v.items(), key=operator.itemgetter(1), reverse=True)}\n",
    "    unigram_filter[k] = dict(itertools.islice(unigram_count[k].items(), 0, 10))\n",
    "    unigram_filter[k].update(dict(itertools.islice(unigram_count[k].items(), len(unigram_count[k]) - 11, len(unigram_count[k]) - 1)))\n",
    "for k, v in bigram_count.items():\n",
    "    bigram_count[k] = {' '.join(vk): vv for (vk, vv) in sorted(v.items(), key=operator.itemgetter(1), reverse=True)}\n",
    "    bigram_filter[k] = dict(itertools.islice(bigram_count[k].items(), 10))\n",
    "    bigram_filter[k].update(dict(itertools.islice(bigram_count[k].items(), len(bigram_count[k]) - 11, len(bigram_count[k]) - 1)))\n",
    "for k, v in trigram_count.items():\n",
    "    trigram_count[k] = {' '.join(vk): vv for (vk, vv) in sorted(v.items(), key=operator.itemgetter(1), reverse=True)}\n",
    "    trigram_filter[k] = dict(itertools.islice(trigram_count[k].items(), 10))\n",
    "    trigram_filter[k].update(dict(itertools.islice(trigram_count[k].items(), len(trigram_count[k]) - 11, len(trigram_count[k]) - 1)))\n",
    "basic_dict = {'count': label_counter, 'length': text_length, 'source': data_source,\n",
    "              'unigram': unigram_count, 'bigram': bigram_count, 'trigram': trigram_count }            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_statistic.json', 'w') as fp:\n",
    "    json.dump(basic_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Vectorizer(Enum):\n",
    "    \"\"\"Methods for feature extraction\"\"\"\n",
    "    Count = 1\n",
    "    TfIdf = 2\n",
    "\n",
    "\n",
    "class Arguments():\n",
    "    \"\"\" Store arguments from command lines. \"\"\"\n",
    "\n",
    "    def __init__(self):        \n",
    "        self.vectorizer = Vectorizer.Count\n",
    "        self.token_pattern = r'(?u)\\b\\w\\w+\\b'\n",
    "        self.ngram = 1        \n",
    "        self.min_df = 0.0\n",
    "        self.max_df = 1.0\n",
    "        self.lowercase = False\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "trainy = le.transform(train_labels)\n",
    "devy = le.transform(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def extract_feature(args, train_data, dev_data):\n",
    "    \"\"\"Extract feature vectors from train data.\n",
    "    \n",
    "    Use CountVectorizer or TfidfVectorizer.\n",
    "    \"\"\"\n",
    "    if args.ngram > 1:\n",
    "        args.token_pattern = r'\\b\\w+\\b'\n",
    "    if args.vectorizer is Vectorizer.Count:\n",
    "        vect = CountVectorizer(lowercase=args.lowercase, ngram_range=(\n",
    "            1, args.ngram), token_pattern=args.token_pattern, min_df=args.min_df, max_df=args.max_df)\n",
    "    elif args.vectorizer is Vectorizer.TfIdf:\n",
    "        vect = TfidfVectorizer(lowercase=args.lowercase, ngram_range=(\n",
    "            1, args.ngram), token_pattern=args.token_pattern, min_df=args.min_df, max_df=args.max_df)\n",
    "    trainX = vect.fit_transform(train_data)    \n",
    "    devX = vect.transform(dev_data)\n",
    "    return trainX, devX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "def train(X, y):\n",
    "    \"\"\"Train a classifie r using the given training data.\n",
    "\n",
    "    Trains logistic regression on the input data with default parameters.\n",
    "    \"\"\"        \n",
    "    cls = LogisticRegression(random_state=0, solver='lbfgs', max_iter=10000)\n",
    "    cls.fit(X, y)\n",
    "    return cls\n",
    "def evaluate(X, yt, cls, name='data'):\n",
    "    \"\"\"Evaluated a classifier on the given labeled data using accuracy.\"\"\"    \n",
    "    yp = cls.predict(X)\n",
    "    acc = metrics.accuracy_score(yt, yp)\n",
    "    print(\"  Accuracy on %s  is: %s\" % (name, acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train_data, dev_data, args):\n",
    "    \"\"\"Tune the hyper-parameters: n-gram, minimum count.\n",
    "\n",
    "    Use the approach of grid search.\n",
    "    \"\"\"    \n",
    "    best_acc = 0\n",
    "    best_f = Vectorizer.Count\n",
    "    best_n = 1\n",
    "    best_min = 0.0\n",
    "    best_max = 1.0\n",
    "    best_lowecase = False\n",
    "    with open(\"grid_search_2.csv\", \"w\", newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        # Tune n-gram and minumum count\n",
    "        csv_writer.writerow(\n",
    "            ['Tokenizer', 'lowercase', 'N-gram', 'Min_df', 'Max_df', 'Accuracy'])\n",
    "        for f in Vectorizer:\n",
    "            args.vectorizer = f\n",
    "            for lowercase in [False]:\n",
    "                args.lowercase = lowercase\n",
    "                for n in range(1, 10):\n",
    "                    args.ngram = n\n",
    "                    for min_v in range(1, 2):\n",
    "                        args.min_df = min_v\n",
    "                        for max_v in range(1110, 1120, 100):\n",
    "                            args.max_df = max_v\n",
    "                            trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "                            cls = train(trainX, trainy)\n",
    "                            dev_acc = evaluate(devX, devy, cls)\n",
    "                            csv_writer.writerow([f, lowercase, n, min_v, max_v, dev_acc])\n",
    "                            if dev_acc > best_acc:\n",
    "                                best_lowercase = lowercase\n",
    "                                best_f = f\n",
    "                                best_acc = dev_acc\n",
    "                                best_n = n\n",
    "                                best_min = min_v\n",
    "                                best_max = max_v\n",
    "    args.vectorizer = best_f\n",
    "    args.min_df = best_min\n",
    "    args.ngram = best_n\n",
    "    args.max_df = best_max\n",
    "    args.lowercase = best_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "grid_search(train_data, dev_data, args)\n",
    "trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "cls = train(trainX, trainy)\n",
    "dev_acc = evaluate(devX, devy, cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write grid search results into Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = []\n",
    "args_count = Arguments()\n",
    "args_count.ngram = 3\n",
    "args_count.f = Vectorizer.Count\n",
    "args_count.min_df = 1\n",
    "args_count.max_df = 1110\n",
    "args_count.lowercase = False\n",
    "args_tfidf = Arguments()\n",
    "args_tfidf.ngram = 5\n",
    "args_tfidf.f = Vectorizer.TfIdf\n",
    "args_tfidf.min_df = 2\n",
    "args_tfidf.max_df = 110\n",
    "args_tfidf.lowercase = False\n",
    "for args in [args_count, args_tfidf]:\n",
    "    trainX, devX = extract_feature(args, train_data, dev_data)\n",
    "    cls = train(trainX, trainy)\n",
    "    yp = cls.predict(devX)\n",
    "    acc = metrics.accuracy_score(devy, yp)\n",
    "    recall = metrics.recall_score(devy, yp)\n",
    "    precision = metrics.precision_score(devy, yp)\n",
    "    f1 = metrics.f1_score(devy, yp)\n",
    "    para_dict.append({'accuracy': acc, 'recall': recall, 'precision': precision, 'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = para_dict[0]\n",
    "tfidf_dict = para_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = []\n",
    "rows_name = ['ngram', 'min', 'max']\n",
    "vects = ['Count', 'TF-IDF']\n",
    "with open('grid_search_typical.csv', newline='', encoding=\"utf8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    vect = None\n",
    "    one_dict = {}\n",
    "    temp_dict = {}\n",
    "    current_name = ''\n",
    "    current_index = 0\n",
    "    for row in csv_reader:\n",
    "        if row[0] in vects:\n",
    "            if vect is None or row[0] != vect:\n",
    "                vect = row[0]\n",
    "                one_dict = {'Vectorizer': vect, 'lowercase': 'False'}\n",
    "                if vect is vects[1]:\n",
    "                    one_dict.update({'score': count_dict})\n",
    "                else:\n",
    "                    one_dict.update({'score': tfidf_dict})\n",
    "                para_dict.append(one_dict)\n",
    "            temp_dict = {}\n",
    "            current_name = row[1]\n",
    "            one_dict.update({row[1]: temp_dict})            \n",
    "        else:            \n",
    "            for i, name in enumerate(rows_name):                \n",
    "                 if name == current_name:                    \n",
    "                    current_index = i + 2\n",
    "            temp_dict[row[current_index]] = row[-1]                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Vectorizer': 'Count',\n",
       "  'lowercase': 'False',\n",
       "  'score': {'accuracy': 0.9350811485642946,\n",
       "   'recall': 0.9264235444657709,\n",
       "   'precision': 0.9396495781959766,\n",
       "   'f1': 0.9329896907216494},\n",
       "  'ngram': {'1': '0.928214732',\n",
       "   '2': '0.941635456',\n",
       "   '3': '0.944132335',\n",
       "   '4': '0.940699126',\n",
       "   '5': '0.938826467',\n",
       "   '6': '0.937578027',\n",
       "   '7': '0.937265918',\n",
       "   '8': '0.936017478',\n",
       "   '9': '0.935393258'},\n",
       "  'min': {'0': '0.944132335',\n",
       "   '1': '0.944132335',\n",
       "   '2': '0.941947566',\n",
       "   '3': '0.939138577',\n",
       "   '4': '0.937578027',\n",
       "   '5': '0.937265918',\n",
       "   '6': '0.936641698',\n",
       "   '7': '0.935081149',\n",
       "   '8': '0.93196005',\n",
       "   '9': '0.933208489',\n",
       "   '10': '0.93164794'},\n",
       "  'max': {'10': '0.917915106',\n",
       "   '110': '0.937890137',\n",
       "   '210': '0.938514357',\n",
       "   '310': '0.937265918',\n",
       "   '410': '0.936017478',\n",
       "   '510': '0.937890137',\n",
       "   '610': '0.938514357',\n",
       "   '710': '0.938202247',\n",
       "   '810': '0.938514357',\n",
       "   '910': '0.940387016',\n",
       "   '1010': '0.940074906',\n",
       "   '1110': '0.944132335',\n",
       "   '1210': '0.943820225',\n",
       "   '1310': '0.942571785',\n",
       "   '1410': '0.942571785',\n",
       "   '1510': '0.940387016',\n",
       "   '1610': '0.940387016',\n",
       "   '1710': '0.939762797',\n",
       "   '1810': '0.939138577',\n",
       "   '1910': '0.938826467',\n",
       "   '2010': '0.940387016'}},\n",
       " {'Vectorizer': 'TF-IDF',\n",
       "  'lowercase': 'False',\n",
       "  'score': {'accuracy': 0.9350811485642946,\n",
       "   'recall': 0.9264235444657709,\n",
       "   'precision': 0.9396495781959766,\n",
       "   'f1': 0.9329896907216494},\n",
       "  'ngram': {'1': '0.88701623',\n",
       "   '2': '0.93071161',\n",
       "   '3': '0.933520599',\n",
       "   '4': '0.933520599',\n",
       "   '5': '0.933832709',\n",
       "   '6': '0.93289638',\n",
       "   '7': '0.93289638',\n",
       "   '8': '0.93289638',\n",
       "   '9': '0.93164794'},\n",
       "  'min': {'0': '0.93102372',\n",
       "   '1': '0.93102372',\n",
       "   '2': '0.933832709',\n",
       "   '3': '0.928214732',\n",
       "   '4': '0.926029963',\n",
       "   '5': '0.923845194',\n",
       "   '6': '0.922284644',\n",
       "   '7': '0.919475655',\n",
       "   '8': '0.913545568',\n",
       "   '9': '0.913545568',\n",
       "   '10': '0.911360799'},\n",
       "  'max': {'10': '0.911048689',\n",
       "   '110': '0.933832709',\n",
       "   '210': '0.93102372',\n",
       "   '310': '0.933520599',\n",
       "   '410': '0.93289638',\n",
       "   '510': '0.93133583',\n",
       "   '610': '0.93133583',\n",
       "   '710': '0.929775281',\n",
       "   '810': '0.929463171',\n",
       "   '910': '0.929775281',\n",
       "   '1010': '0.929775281'}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('performance.json', 'w') as fp:\n",
    "    json.dump(para_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
